{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture #05 Exploring Data with pandas.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WAcXh6j8sySe",
        "toc-hr-collapsed": true
      },
      "source": [
        "## 1 Exploring Data with pandas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TvYRdrKt_M8Y"
      },
      "source": [
        "### 1.1 Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Niv9xgJzqeB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "In pandas, each axis has labels, and we've learned to use loc[] to specify labels to create our selection:\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=19qbWRXXH0SrBu2FnMREay_KyvifucKNd\">\n",
        "\n",
        "\n",
        "In some scenarios, like specifying specific columns, using labels to make selections makes things easier - in others though, it makes things harder. If you wanted to select the tenth to twentieth rows in a dataframe, you'd need to know their labels first.\n",
        "\n",
        "In this lesson, we'll learn how to index by integer position with pandas. We'll also learn more advanced selection techniques which will help us perform more complex data analysis.\n",
        "\n",
        "We'll continue to use the Fortune Global 500 (2017) dataset from the previous lesson."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-1zPyxT4BlDt"
      },
      "source": [
        "### 1.2 Using iloc to select by integer position\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awaWEXwa0B4f",
        "colab_type": "text"
      },
      "source": [
        "To select data by integer position using pandas we use the [Dataframe.iloc[]](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html) method and the [Series.iloc[]](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.iloc.html) method. It's easy to get loc[] and iloc[] confused at first, but the easiest way is to remember the first letter of each method:\n",
        "\n",
        "- **loc**: **l**able based selection\n",
        "- **iloc**: **integer** position based selection\n",
        "\n",
        "Using the **iloc[]** methods is almost identical to indexing with NumPy, with integer positions starting at **0** like ndarrays and Python lists. Let's take a look at how we would perform our selection from the previous screen using **iloc[]:**\n",
        "\n",
        "<img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1dQa9Y1ZVbYHCA0BhQxWL5FPgJVPAyU1P\">\n",
        "\n",
        "\n",
        "As you can see, **DataFrame.iloc[]** behaves similarly to **DataFrame.loc[]**. The full syntax for **DataFrame.iloc[]**, in psuedocode, is:\n",
        "\n",
        "```python\n",
        "df.iloc[row,column]\n",
        "```\n",
        "\n",
        "The valid inputs for row and column are almost identical to when you use **DataFrame.loc[]**, with the distinction being that you are using integers rather than labels:\n",
        "\n",
        "- A single integer position.\n",
        "- A list or array of integer positions.\n",
        "- A slice object with integer positions.\n",
        "- A boolean array.\n",
        "\n",
        "Let's say we wanted to select just the first column from our **f500** dataframe. To do this, we use the : wildcards to specify all rows, and then use the integer 0 to specify the first column:\n",
        "\n",
        "```python\n",
        "first_column = f500.iloc[:,0]\n",
        "print(first_column)\n",
        "```\n",
        "```python\n",
        "0                        Walmart\n",
        "1                     State Grid\n",
        "2                  Sinopec Group\n",
        "...\n",
        "497    Wm. Morrison Supermarkets\n",
        "498                          TUI\n",
        "499                   AutoNation\n",
        "Name: company, dtype: object\n",
        "```\n",
        "\n",
        "If we wanted to select a single row, we don't need to specify a column wildcard. Let's see how we'd select just the fourth row:\n",
        "\n",
        "```python\n",
        "fourth_row = f500.iloc[3]\n",
        "print(fourth_row)\n",
        "```\n",
        "```python\n",
        "company                 China National Petroleum\n",
        "rank                                           4\n",
        "revenues                                  262573\n",
        "revenue_change                             -12.3\n",
        "profits                                   1867.5\n",
        "assets                                    585619\n",
        "profit_change                              -73.7\n",
        "ceo                                Zhang Jianhua\n",
        "industry                      Petroleum Refining\n",
        "sector                                    Energy\n",
        "previous_rank                                  3\n",
        "country                                    China\n",
        "hq_location                       Beijing, China\n",
        "website                   http://www.cnpc.com.cn\n",
        "years_on_global_500_list                      17\n",
        "employees                                1512048\n",
        "total_stockholder_equity                  301893\n",
        "Name: 3, dtype: object\n",
        "```\n",
        "\n",
        "If we are specifying a positional slice, we can take advantage of the same shortcut that we use with labels, using brackets without **loc**. Here's how we would select the rows between index positions one up to and including four:\n",
        "\n",
        "```python\n",
        "second_to_fifth_rows = f500[1:5]\n",
        "```\n",
        "\n",
        "```python\n",
        "company  rank  revenues ... employees  total_stockholder_equity\n",
        "1         State Grid     2    315199 ...    926067                    209456\n",
        "2      Sinopec Group     3    267518 ...    713288                    106523\n",
        "3  China National...     4    262573 ...   1512048                    301893\n",
        "4       Toyota Motor     5    254694 ...    364445                    157210\n",
        "```\n",
        "\n",
        "In the example above, the row at index position 5 is not included, just like if we were slicing with a Python list. It's worth reiterating again that **iloc[]** handles slicing differently, as we learned in the previous mission:\n",
        "\n",
        "- With **loc[]**, the **ending slice is included.**\n",
        "- With **iloc[]**, the **ending slice is not included.**\n",
        "\n",
        "The table below summarizes how we can use **DataFrame.iloc[]** and **Series.iloc[]** to select by integer position:\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=18jhblUrPsASHHdT5Lgpr6mmPmaIYo6og\">\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "We have provided code to read the **f500.csv** file into a dataframe and assigned it to **f500**, and inserted **NaN** values into the **previous_rank** column as we did in the previous section.\n",
        "\n",
        "- Select just the fifth row of the **f500** dataframe, assigning the result to **fifth_row.**\n",
        "- Select the first three rows of the **f500** dataframe, assigning the result to **first_three_rows.**\n",
        "- Select the first and seventh rows and the first 5 columns of the **f500** dataframe, assigning the result to **first_seventh_row_slice**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1MTPfNm7AD3J",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "f500 = pd.read_csv(\"f500.csv\", index_col=0)\n",
        "f500.index.name = None\n",
        "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gGUK5R5HFOmV"
      },
      "source": [
        "### 1.3 Reading CSV files with pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Xb7brp0-VW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "So far, we've provided the code to read the CSV file into pandas for you. In this mission, we're going to teach you how to use the [pandas.read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function to read in CSV files. Before we start, let's take a look at the first few lines of our CSV file in its raw form. To make it easier to read, we're only showing the first four columns from each line:\n",
        "\n",
        "```python\n",
        "company,rank,revenues,revenue_change\n",
        "Walmart,1,485873,0.8\n",
        "State Grid,2,315199,-4.4\n",
        "Sinopec Group,3,267518,-9.1\n",
        "China National Petroleum,4,262573,-12.3\n",
        "Toyota Motor,5,254694,7.7\n",
        "```\n",
        "\n",
        "Now let's take a moment to look at the code segment we've been using to read in the files.\n",
        "\n",
        "```python\n",
        "f500 = pd.read_csv(\"f500.csv\", index_col=0)\n",
        "f500.index.name = None\n",
        "```\n",
        "\n",
        "\n",
        "Looking at the first line only, we use the **pandas.read_csv()** function with an unnamed argument, the name of the CSV file, and a named argument for the **index_col** parameter. The **index_col** parameter specifies which column to use as the row labels. We use a value of **0** to specify that we want to use the first column.\n",
        "\n",
        "Let's look at what the **f500** dataframe looks like after that first line. We'll use **DataFrame.iloc[]** to show the first 5 rows and the first 3 columns:\n",
        "\n",
        "```python\n",
        ">>> f500 = pd.read_csv(\"f500.csv\", index_col=0)\n",
        "\n",
        ">>> print(f500.iloc[:5, :3])\n",
        "\n",
        "                              rank  revenues  revenue_change\n",
        "    company                                                    \n",
        "    Walmart                      1    485873             0.8\n",
        "    State Grid                   2    315199            -4.4\n",
        "    Sinopec Group                3    267518            -9.1\n",
        "    China National Petroleum     4    262573           -12.3\n",
        "    Toyota Motor                 5    254694             7.7\n",
        "```\n",
        "\n",
        "Notice that above the index labels is the text **company**. This is the value from the start of the first row of the CSV, effectively the name of the first column. Pandas has used this value as the **axis name** for the index axis. Both the column and index axes can have names assigned to them. The next line of code removes that name:\n",
        "\n",
        "```python\n",
        "f500.index.name = None\n",
        "```\n",
        "\n",
        "First, we use **DataFrame.index** to access the index axes attribute, and then we use **index.name** to access the name of the index axes. By setting this to **None** we remove the name. Let's look at what it looks like after this action\n",
        "\n",
        "```python\n",
        ">>> f500.index.name = None\n",
        "\n",
        ">>> print(f500.iloc[:5, :3])\n",
        "\n",
        "                              rank  revenues  revenue_change\n",
        "    Walmart                      1    485873             0.8\n",
        "    State Grid                   2    315199            -4.4\n",
        "    Sinopec Group                3    267518            -9.1\n",
        "    China National Petroleum     4    262573           -12.3\n",
        "    Toyota Motor                 5    254694             7.7\n",
        "```\n",
        "\n",
        "The index name has been removed.\n",
        "\n",
        "The **index_col** parameter we used is an optional argument. Let's look at what it looks like if we use **pandas.read_csv()** without it:\n",
        "\n",
        "```python\n",
        ">>> f500 = pd.read_csv(\"f500.csv\")\n",
        "\n",
        ">>> print(f500.iloc[:5,:3])\n",
        "\n",
        "                        company  rank  revenues\n",
        "    0                   Walmart     1    485873\n",
        "    1                State Grid     2    315199\n",
        "    2             Sinopec Group     3    267518\n",
        "    3  China National Petroleum     4    262573\n",
        "    4              Toyota Motor     5    254694\n",
        "```\n",
        "\n",
        "There two differences with this approach:\n",
        "\n",
        "- The **company** column is now included as a regular column, instead of being used for the index.\n",
        "- The index labels are now integers starting from **0**.\n",
        "- This is the more conventional way to read in a dataframe, and it's the method we'll use from here on in. There are a few things to be aware of when you have an integer index labels, and we'll talk about them in the next screen.\n",
        "\n",
        "\n",
        "For now, let's re-read in the CSV file using the conventional method:\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "The pandas library is already imported from the previous screen.\n",
        "\n",
        "- Use the **pandas.read_csv()** function to read the **f500.csv** CSV file as a pandas dataframe, and assign it to the variable name **f500**.\n",
        "  - Do not use the **index_col** parameter, so that the dataframe has integer index labels.\n",
        "- Use the code below to insert the **NaN** values into the **previous_rank** column: \n",
        "```python\n",
        "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7YDIZ_uOG5S5",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zxq9CFkx6-lZ"
      },
      "source": [
        "### 1.4 Working with Integer Labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRZ6gjFR1pIN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "As we observed in the previous subsection, our index labels are now integers compared with previously where all our index labels were strings. As a result, this means, that while our dataframe has all of the rows, in the same order, as when we read it in, that the integer position and the label for the index axis is the same. Let's look at an example:\n",
        "\n",
        "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1VeQE7W6ylvfg524QrO2tJ_-iFRud_04F\">\n",
        "\n",
        "\n",
        "Because the index axis of our dataframe has labels that are identical to the integer positions, both **loc[]** and **iloc[]** give the same result. But what if we have modified our dataframe in some way. Let's reorder the rows of our dataframe, and then see what happens:\n",
        "\n",
        "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1KT2Dus_gxSDfPeBSSxqNkoU8NWXJFlVk\">\n",
        "\n",
        "Now we get different results. When we use **df.iloc[1]** it still selects the second row, since **DataFrame.iloc[]** uses integer position. However, **df.loc[1]** selects the **third row– DataFrame.loc[]** itself doesn't mind that the rows are out of order, it just looks at the axis labels and selects the row with the matching label.\n",
        "\n",
        "This is one of the most confusing parts of selecting data with pandas. You might not come across it often, because a lot of the time you'll work with a dataframe where the index labels are integers, and the dataframe contains all of its original rows, in order. You can use **DataFrame.iloc[]** and **DataFrame.loc[]** interchangeably and it doesn't matter which you chose.\n",
        "\n",
        "Then, you remove some rows or change the order, and suddenly you're getting errors or unexpected behavior. For this reason, it's important to make sure that when you're selecting data you're always asking yourself, \"Do I want to select based on position or label?\" and choosing **DataFrame.iloc** or **DataFrame.loc[]** accordingly. Let's look at some examples with our **f500** dataframe where we come across this 'gotcha' to do with integer labels.\n",
        "\n",
        "Let's say that we wanted to select just the Swedish companies from the Fortune 500:\n",
        "\n",
        "```python\n",
        ">>> swedish = f500.loc[f500[\"country\"] == \"Sweden\",\"company\":\"revenues\"]\n",
        "\n",
        ">>> print(swedish)\n",
        "\n",
        "                        company  rank  revenues\n",
        "    300                   Volvo   301     35269\n",
        "    418             LM Ericsson   419     26004\n",
        "    481  H & M Hennes & Mauritz   482     22618\n",
        "```\n",
        "\n",
        "If we wanted to select the first company from our new swedish dataframe, we can use **DataFrame.iloc[]**:\n",
        "\n",
        "```python\n",
        ">>> first_swedish = swedish.iloc[0]\n",
        "\n",
        ">>> print(first_swedish)\n",
        "\n",
        "    company     Volvo\n",
        "    rank          301\n",
        "    revenues    35269\n",
        "    Name: 300, dtype: object\n",
        "```\n",
        "\n",
        "Let's see what happens when we use **DataFrame.loc[]** instead of **DataFrame.iloc[]**:\n",
        "\n",
        "```python\n",
        ">>> first_swedish = swedish.loc[0]\n",
        "\n",
        "    ---------------------------------------------------------------------------\n",
        "    KeyError                                  Traceback (most recent call last)\n",
        "    /python3.4/site-packages/pandas/core/indexing.py in _has_valid_type(self, key, axis)\n",
        "       1410                 if key not in ax:\n",
        "    -> 1411                     error()\n",
        "       1412             except TypeError as e:\n",
        "\n",
        "    /python3.4/site-packages/pandas/core/indexing.py in error()\n",
        "       1405                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n",
        "    -> 1406                                (key, self.obj._get_axis_name(axis)))\n",
        "       1407 \n",
        "\n",
        "    KeyError: 'the label [0] is not in the [index]'\n",
        "```\n",
        "\n",
        "We get an error, telling us that **the label [0] is not in the [index]** (the actual traceback for this error is much longer than this, we have truncated it for brevity). And indeed, there is no row that has a label **0** in the index of our **swedish** dataframe.\n",
        "\n",
        "The four most common times we will see this is when we alter the rows in our dataframe by:\n",
        "\n",
        "1. Selecting a subset of the data (like in the example above).\n",
        "2. Removing certain rows, for example if they have null values (which we'll explore in the next mission).\n",
        "3. Randomizing the order of the rows in our dataframe (which is commonly done to perform machine learning).\n",
        "4. Sorting the rows.\n",
        "\n",
        "Regardless of how we altered the dataframe, the way to avoid this is the same: Always think carefully and deliberately about whether you want to select by label or integer position, and use **DataFrame.loc[]** or **DataFrame.iloc[]** accordingly.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "In the code below, we have used the [DataFrame.sort_values()](https://www.dataquest.io/m/292/exploring-data-with-pandas/4/working-with-integer-labels) method to sort the rows in the **f500** dataframe by the employees column from most to least employees, and have assigned the resulting dataframe to **sorted_emp**.\n",
        "\n",
        "  - Assign the first five rows of the **sorted_emp** dataframe to the variable **top5_emp**, by choosing the correct method out of either **loc[]** or **iloc[].**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9cR5waV97v9s",
        "colab": {}
      },
      "source": [
        "sorted_emp = f500.sort_values(\"employees\", ascending=False)\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FkB9rNiSA-tL"
      },
      "source": [
        "### 1.5 Using pandas methods to create boolean masks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbJPh4m62E7k",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We've previously used the Python boolean operators like >, <, and **==** to create boolean masks to select subsets of data. There are also a number of pandas methods that return boolean masks that are useful for working with an exploring data.\n",
        "\n",
        "You might have noticed that for companies from the USA, the **hq_location** column contains both the city and state that the company is headquartered in:\n",
        "\n",
        "```python\n",
        ">>> usa_hqs = f500.loc[f500[\"country\"] == \"USA\", \"hq_location\"]\n",
        "\n",
        ">>> print(usa_hqs.head())\n",
        "\n",
        "    0       Bentonville, AR\n",
        "    7             Omaha, NE\n",
        "    8         Cupertino, CA\n",
        "    9            Irving, TX\n",
        "    10    San Francisco, CA\n",
        "    Name: hq_location, dtype: object\n",
        "```\n",
        "\n",
        "The two letters at the end of each of these values represent the state within the USA: AR for Arkansas, NE for Nebreska, CA for California, and TX for Texas. If we wanted to look at only companies headquartered in California, it would be useful to be able to create a boolean mask based on the text within these values.\n",
        "\n",
        "There are two pandas methods that we could use to achieve this: the [Series.str.contains()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.contains.html) method and the [Series.str.endswith()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.endswith.html) method. The Series.str.contains() method is a vectorized version of Python's in operator:\n",
        "\n",
        "```python\n",
        ">>> name = \"Michael Johnson\"\n",
        "\n",
        ">>> \"Michael\" in name\n",
        "\n",
        "    True\n",
        "\n",
        ">>> \"John\" in name\n",
        "\n",
        "    True\n",
        "\n",
        ">>> \"Eric\" in name\n",
        "\n",
        "    False\n",
        "```\n",
        "\n",
        "In contrast, **Series.str.endswith()** is a vectorized version of the Python string **str.endswith()** method , which is probably a better option for our purposes, as it will ensure that we don't get any stray matches. This is how we could go about it:\n",
        "\n",
        "\n",
        "```python\n",
        ">>> usa = f500.loc[f500[\"country\"] == \"USA\"]\n",
        "\n",
        ">>> print(usa[\"hq_location\"].head())\n",
        "\n",
        "    0       Bentonville, AR\n",
        "    7             Omaha, NE\n",
        "    8         Cupertino, CA\n",
        "    9            Irving, TX\n",
        "    10    San Francisco, CA\n",
        "    Name: hq_location, dtype: object\n",
        "\n",
        ">>> is_california = usa[\"hq_location\"].str.endswith(\"CA\")\n",
        "\n",
        ">>> print(is_california.head())\n",
        "\n",
        "    0     False\n",
        "    7     False\n",
        "    8      True\n",
        "    9     False\n",
        "    10     True\n",
        "    Name: hq_location, dtype: bool\n",
        "\n",
        ">>> california = usa[is_california]\n",
        "\n",
        ">>> print(california.iloc[:5,:3])\n",
        "\n",
        "            company  rank  revenues\n",
        "    8         Apple     9    215639\n",
        "    10     McKesson    11    198533\n",
        "    44      Chevron    45    107567\n",
        "    60  Wells Fargo    61     94176\n",
        "    64     Alphabet    65     90272\n",
        "```\n",
        "\n",
        "We won't use it in this mission, but you should also be aware of the [Series.str.startswith()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.startswith.html) method, a vectorized version of the Python string [str.startswith()](https://docs.python.org/3.6/library/stdtypes.html#str.startswith) method and can be used to create boolean masks based on the start of string values.\n",
        "\n",
        "Another pair of handy pandas methods that create boolean masks is the [Series.isnull()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.isnull.html) method and [Series.notnull()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.notnull.html) method. These return boolean masks that you can use to select either rows that contain null (or NaN) values for a certain column, or inversely those rows that don't. These can be particularly useful for identifying and exploring the rows in a dataframe.\n",
        "\n",
        "Let's see the **Series.isnull()** method in action to look at the rows that have null values in the **revenue_change** column.\n",
        "\n",
        "```python\n",
        ">>> rev_change_null = f500[f500[\"revenue_change\"].isnull()]\n",
        "\n",
        ">>> print(rev_change_null[[\"company\",\"country\",\"sector\"]])\n",
        "\n",
        "                            company  country      sector\n",
        "    90                       Uniper  Germany      Energy\n",
        "    180  Hewlett Packard Enterprise      USA  Technology\n",
        "```\n",
        "\n",
        "We can see that the two companies with missing values for the **revenue_change** column is Uniper, a German energy company; and Hewlett Parkard Enterprise, an American technology company. Let's use what we've learned to calculate ranking change for the companies that were ranked last year.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Use the **Series.notnull()** method to select all rows from **f500** that have a non-null value for the **previous_rank** column, and assign the result to **previously_ranked**\n",
        "- From the **previously_ranked** dataframe, subtract the previous_rank column from the rank column, and assign the result to **rank_change.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r7O2wSLbHKdy",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v7pZdYw9IzeM"
      },
      "source": [
        "### 1.6 Boolean Operators\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak1BmlRf2bEP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Boolean indexing is a powerful tool which allows us to select or exclude parts of our data based on their values to perform analysis. There are however, some questions that we can't yet answer, like:\n",
        "\n",
        "- Which companies have over 100 billion in revenue and also have revenue growth of more than 10%?\n",
        "- What are the top 5 technology companies outside the USA?\n",
        "\n",
        "All of these questions have two or more parts that depend on the values. As an example, to answer the first question we would have to identify all the companies that have over 100 billion in revenue and also have revenue growth of more than 10%. To do this, we need to learn how to combine boolean arrays.\n",
        "\n",
        "To recap, boolean arrays are created using any of the Python standard **comparison operators**: **==** (equal), **>** (greater than), **<** (less than), **!=** (not equal).\n",
        "\n",
        "We combine boolean arrays using **boolean operators**. In Python, these boolean operators are **and**, **or**, and **not**. In pandas, the operators are slightly different:\n",
        "\n",
        "\n",
        "| pandas | Python equivalent | Meaning |\n",
        "|--------|-------------------|-------------------------------------------|\n",
        "| a & b | a and b | True if both a and b are True, else False |\n",
        "| a $|$ b | a or b | True if either a or b is True |\n",
        "| ~a | not a | True if a is False, else False |\n",
        "\n",
        "\n",
        "Let's look at how these boolean operators work across pandas series objects, using two example series objects, **a** and **b**:\n",
        "\n",
        "\n",
        "<img width=\"200\" src=\"https://drive.google.com/uc?export=view&id=1911_tZkilBFq50Qeojr8E41aTBBNQbta\">\n",
        "\n",
        "We'll start by using the & operator to perform a boolean **'and'**:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1ZdBex9EhkUA42_IzUAsbxnFU4w5-Upkg\">\n",
        "\n",
        "Let's look at what happens when we use $|$ to perform a boolean 'or':\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1TZqw-H0A-59yCkpDKrHIeVex5lHIEhEk\">\n",
        "\n",
        "Lastly, let's look at what happens when we use ~ to perform a boolean 'not':\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1llHLeYGNC_mtDT0qttPD9sZTJnRAwoA1\">\n",
        "\n",
        "\n",
        "Let's test our understanding of how boolean operators work with some multiple choice exercises:\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "Looking at the dataframe and code below, chose the series that matches the result of the boolean operation and assign the integer 1, 2, or 3 to **answer_1**.\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1EaFFoKazQIrAYd2tWuSSgXfePQ0nqcGm\">\n",
        "\n",
        "\n",
        "Looking at the dataframe and code below, chose the series that matches the result of the boolean operation and assign the integer 1, 2, or 3 to **answer_2.**\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1NgbMDdJ_oPL12pTVfCGBfv-_HX7Wl327\">\n",
        "\n",
        "Looking at the dataframe and code below, chose the series that matches the result of the boolean operation and assign the integer 1, 2, or 3 to **answer_3.**\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1-CZEjG5SY9Ho2alht_LjA47kKdecXA4A\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bYdP2hLwI_50"
      },
      "source": [
        "### 1.7 Using Boolean Operators\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN76DN402kK4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Let's look at how we use boolean operators to combine multiple boolean comparisons in practice. We'll use **f500_sel**, a small selection of our f500 dataframe:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1jR7JlIVoPzYkjy_xfpvYEaCXvikUK3qU\">\n",
        "\n",
        "\n",
        "We want to find the companies in **f500_sel** with more than 265 billion in revenue that are headquarted in China. We'll start by performing two boolean comparisons to produce two separate boolean arrays; One based on revenue, and one based on country (the revenue column is already in millions).\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1SVde3lAUEGVt69qDE7_9LHyjI80A-2_s\">\n",
        "\n",
        "We then use the & operator to combine the two boolean arrays using boolean 'and' logic:\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1fefm6MA1piKONeawWn94ocbUZzb7KF4a\">\n",
        "\n",
        "\n",
        "Lastly, we use the combined boolean array to perform selection on our dataframe:\n",
        "\n",
        "\n",
        "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1f5tAqGgDvn_faQcSK8CzSC7e3NTRII11\">\n",
        "\n",
        "\n",
        "The result give us the two companies from **f500_sel** that are both Chinese and have over 265 billion in revenue. Just like when we use a single boolean array to perform selection, when using multiple boolean arrays with boolean operators we don't need to assign things to intermediate variables. Let's look at how we can streamline the code from the example above. First, let's look at the code as one segment:\n",
        "\n",
        "```python\n",
        "cols = [\"company\", \"revenues\", \"country\"]\n",
        "final_cols = [\"company\", \"revenues\"]\n",
        "\n",
        "f500_sel = f500[cols].head()\n",
        "over_265 = f500_sel[\"revenues\"] > 265000\n",
        "china = f500_sel[\"country\"] == \"China\"\n",
        "combined = over_265 & china\n",
        "result = f500_sel.loc[combined,final_cols]\n",
        "```\n",
        "\n",
        "The first place we can optimize our code is by making our two boolean comparisons, with their boolean operator in a single line, instead of assigning them to the intermediate **china** and **over_265** variables first:\n",
        "\n",
        "\n",
        "```python\n",
        "combined = (f500_sel[\"revenues\"] > 265000) & (f500_sel[\"country\"] == \"China\")\n",
        "```\n",
        "\n",
        "We have used parentheses around each of our boolean comparisons. This is very important– **our boolean operation will fail without parentheses**. Lastly, instead of assigning the boolean arrays to **combined**, we can insert the comparison directly into our selection:\n",
        "\n",
        "```python\n",
        "result = f500_sel.loc[(f500_sel[\"revenues\"] > 265000) & (f500_sel[\"country\"] == \"China\"), final_cols]\n",
        "```\n",
        "\n",
        "Whether to perform this final state is very much a matter of taste. As always, your decision should be driven by what will make your code more readable. Cramming everything into one line is not always the best option.\n",
        "\n",
        "Let's practice more complex selection using boolean operators\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Select from the **f500** dataframe:\n",
        "  - Companies with revenues over 100 billion and negative profits, assigning the result to **big_rev_neg_profit**.\n",
        "  - The first 5 companies in the Technology sector that are not headquartered in the USA, assigning the result to **tech_outside_usa**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AiY27nPZ-VMc",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ow84417-A5Ph"
      },
      "source": [
        "### 1.8 Pandas Index Alignment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NTJNTo32tT3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "So far, we've only seen examples where the dataframe and series objects we're working with have matching index labels. One of the most powerful aspects of pandas is that almost every operation will **align on the index labels**. Let's look at an example– below we have a dataframe **food** and a **series** colors:\n",
        "\n",
        "<img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1_LAUprnXe3BYUgUg2r5fS2kfPpoTtdgt\">\n",
        "\n",
        "Both the **food** dataframe and the **colors** series have the same index labels, however they are in totally different orders. As an example, the first row of **food** has the index label **tomato**, and the first item of **colors** has the index label **corn**.\n",
        "\n",
        "If we wanted to add **colors** as a new column in our **food** dataframe, we can use the following code:\n",
        "\n",
        "```python\n",
        "food[\"color\"] = colors\n",
        "```\n",
        "\n",
        "When we do this, pandas will ignore the order of the colors series, and align on the index labels:\n",
        "\n",
        "<img width=\"350\" src=\"https://drive.google.com/uc?export=view&id=1zD-HqxfZ8yUj_4pNrbQasrnASTX0zhQE\">\n",
        "\n",
        "The result of our code operation is the dataframe below:\n",
        "\n",
        "<img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1hDfSi-D5sJf788MlGOI63vmAlLYrVIYU\">\n",
        "\n",
        "\n",
        "We can see that pandas has done all the hard work for us, and we don't have to worry about the fact that our series and dataframe were ordered differently. Let's look at another example. Say we had the series **alt_name** below:\n",
        "\n",
        "<img width=\"200\" src=\"https://drive.google.com/uc?export=view&id=1jMt7P6e0d7X8yaE2kLm0gPzaCxQtS30F\">\n",
        "\n",
        "\n",
        "The **alt_name** series only has three items. The first item, with index label **arugula** doesn't have a corresponding row in the **food** dataframe, where the other two do. Let's see what happens when we assign this as a new column:\n",
        "\n",
        "```python\n",
        "food[\"alt_name\"] = alt_name\n",
        "```\n",
        "\n",
        "<img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1Vs-aLaUmDmdqUtDPt6_Eh7B3T6d3Wvhx\">\n",
        "\n",
        "\n",
        "In this scenario, pandas:\n",
        "\n",
        "- Discards any items that have an index that doesn't match the dataframe.\n",
        "- Aligns on the index labels for the values that do match the dataframe.\n",
        "- Fills any remaining rows with **NaN**\n",
        "\n",
        "If we assign a new column with no matching index labels, pandas follows the same three steps above, but as there are no matching labels, all rows in the new column will be **NaN** values.\n",
        "\n",
        "The pandas library will align on index at every opportunity - this makes working with data from different sources, or working with data when you have removed, added, or reordered rows much easier than it would be otherwise. This works whether your index labels are strings or integers - as long as you haven't made modifications to the index labels, you can use index alignment to our advantage.\n",
        "\n",
        "Let's practice this using our Fortune 500 data.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "Earlier, we created the **rank_change** series by performing vectorized subtraction only on rows without null values. We have included the code again as a reminder.\n",
        "\n",
        "- Assign the values in the **rank_change** to a new column in the **f500** dataframe, **\"rank_change\".**\n",
        "- Once you have run your code, use the variable inspector to look at the **f500** dataframe and observe how the new column aligns with the existing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KxTo6msfCcF7",
        "colab": {}
      },
      "source": [
        "previously_ranked = f500[f500[\"previous_rank\"].notnull()]\n",
        "rank_change = previously_ranked[\"previous_rank\"] - previously_ranked[\"rank\"]\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-YKQxivqGGGJ"
      },
      "source": [
        "### 1.9 Using Loops with pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW-AT1QN2yGU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "So far, we've explicitly avoided doing anything with loops using pandas. Because one of the key benefits of pandas is that it has vectorized methods to work with data more efficiently, we want to avoid using loops wherever we can.\n",
        "\n",
        "As an illustration, let's look at one common pattern that you might be tempted to use a loop for, and how we can use a vectorized operation to replace it. Let's try and replace all of the values in the column **B** a dataframe:\n",
        "\n",
        "```python\n",
        ">>> print(df)\n",
        "\n",
        "       A  B  C\n",
        "    x  6  1  0\n",
        "    y  1  8  8\n",
        "    z  3  8  7\n",
        "\n",
        ">>> for row in df:\n",
        "        if row[\"B\"] == 8:\n",
        "            row[\"B\"] = 99\n",
        "\n",
        "    ---------------------------------------------------\n",
        "    TypeError                                 Traceback\n",
        "    <ipython-input-17-baf1fd443d29> in module()\n",
        "          1 for row in df:\n",
        "    ----> 2     if row[\"B\"] == 8:\n",
        "          3         row[\"B\"] = 99\n",
        "\n",
        "    TypeError: string indices must be integers\n",
        "</ipython-input-17-baf1fd443d29>\n",
        "```\n",
        "\n",
        "In this code, we attempted to loop over every row of the dataframe, check the value for a particular column, and if it matches our check, we change it. Unfortunately, our code produced an error.\n",
        "\n",
        "When you attempt to loop over a dataframe, it returns the column index labels, rather than the rows as we might expect. There are pandas methods to help loop over dataframes, but they should be only used as a last resort, and can almost always be avoided (we'll learn about those methods in a later course).\n",
        "\n",
        "```python\n",
        ">>> print(df)\n",
        "\n",
        "       A  B  C\n",
        "    x  6  1  0\n",
        "    y  1  8  8\n",
        "    z  3  8  7\n",
        "\n",
        ">>> for i in df:\n",
        "        print(i)\n",
        "\n",
        "    A\n",
        "    B\n",
        "    C\n",
        "```\n",
        "\n",
        "Instead of trying to use loops, we can perform the same operation quickly and easily using vectorized operations:\n",
        "\n",
        "```python\n",
        ">>> df.loc[df[\"B\"] == 8, \"B\"] = 99\n",
        "\n",
        ">>> print(df)\n",
        "\n",
        "       A   B  C\n",
        "    x  6   1  0\n",
        "    y  1  99  8\n",
        "    z  3  99  7\n",
        "```\n",
        "\n",
        "One scenario where it is useful to use loops with pandas is when we are performing aggregation. Aggregation is where we apply a statistical operation to groups of our data. Let's say that we wanted to work out what the average revenue was for each country in the data set. Our process might look like this:\n",
        "\n",
        "- Identify each unique country in the data set.\n",
        "- For each country:\n",
        "  - Select only the rows corresponding to that country.\n",
        "  - Calculate the average revenue for those rows.\n",
        "\n",
        "In this process, we can use a loop to iterate over the countries. We'll still use vectorized operations to select the right rows and calculate the means, so our calculation remains fast. To identify the unique countries, we can use the [Series.unique() method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html). This method returns an array of unique values from any series. Once we have that, we can loop over that array and perform our operation. We'll use a dictionary to store the results. Here's what that looks like:\n",
        "\n",
        "\n",
        "```python\n",
        "# Create an empty dictionary to store the results\n",
        "avg_rev_by_country = {}\n",
        "\n",
        "# Create an array of unique countries\n",
        "countries = f500[\"country\"].unique()\n",
        "\n",
        "# Use a for loop to iterate over the countries\n",
        "for c in countries:\n",
        "    # Use boolean comparison to select only rows that\n",
        "    # correspond to a specific country\n",
        "    selected_rows = f500[f500[\"country\"] == c]\n",
        "    # Calculate the mean average revenue for just those rows\n",
        "    mean = selected_rows[\"revenues\"].mean()\n",
        "    # Assign the mean value to the dictionary, using the\n",
        "    # country name as the key\n",
        "    avg_rev_by_country[c] = mean\n",
        "```\n",
        "\n",
        "\n",
        "The resulting dictionary is below (we've shown just the first few keys):\n",
        "\n",
        "```python\n",
        "{'Australia': 33688.71428571428,\n",
        " 'Belgium': 45905.0,\n",
        " 'Brazil': 52024.57142857143,\n",
        " 'Britain': 51588.708333333336,\n",
        " 'Canada': 31848.0,\n",
        " 'China': 55397.880733944956,\n",
        " 'Denmark': 35464.0,\n",
        " ...\n",
        " }\n",
        "```\n",
        "\n",
        "We'll practice this pattern to calculate the company that employs the most people in each country. To do this extra step, we'll use the [DataFrame.sort_values()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html) method to sort our dataframe so we can then select the first row which will give us our largest value.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "In this exercise, we're going to produce the following dictionary of the top employer in each country:\n",
        "\n",
        "```python\n",
        "{'Australia': 'Wesfarmers',\n",
        " 'Belgium': 'Anheuser-Busch InBev',\n",
        " 'Brazil': 'JBS',\n",
        " ...\n",
        " 'U.A.E': 'Emirates Group',\n",
        " 'USA': 'Walmart',\n",
        " 'Venezuela': 'Mercantil Servicios Financieros'}\n",
        "```\n",
        "\n",
        "- Read the documentation for the [DataFrame.sort_values() method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html) to familiarize yourself with the syntax. You will need to use only the **by** and **ascending** parameters to complete this exercise.\n",
        "- Create an empty dictionary, **top_employer_by_country** to store the results of the exercise.\n",
        "- Use the **Series.unique()** method to create an array of unique values from the **country** column.\n",
        "- Use a for loop to iterate over the array unique countries, and in each iteration:\n",
        "  - Select only the rows that have a country name equal to the current iteration.\n",
        "  - Use **DataFrame.sort_values()** to sort those rows by the **employees** column in descending order.\n",
        "  - Select the first row from the sorted dataframe.\n",
        "  - Extract the company name from the index label **company** from the first row.\n",
        "  - Assign the results to the **top_employer_by_country** dictionary, using the country name as the key, and the company name as the value.\n",
        "- When you have run your code, use the variable inspector to view the top employer for each country.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QgwfYiJnLtyq",
        "colab": {}
      },
      "source": [
        "# put your code here\n",
        "# can you do it using just one code line?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DonEC76kNRy8"
      },
      "source": [
        "## 2 Challenge: Calculating Return on Assets by Sector\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fljK-Kz3QAB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Now it's time for a challenge to bring everything together! In this challenge we're going to add a new column to our dataframe, and then perform some aggregation using that new column.\n",
        "\n",
        "The column we create is going to contain a metric called [return on assets (ROA)](https://www.inc.com/encyclopedia/return-on-assets-roa.html). ROA is a business-specific metric which inicates a companies ability to make profit using their available assets.\n",
        "\n",
        "$\n",
        "\\textrm{return on assets} = \\frac{profits}{assets}\n",
        "$\n",
        "\n",
        "Once we've created the new column, we'll aggregate by sector, and find the company with the highest ROA from each sector. Like previous challenges, we'll provide some guidance in the hints, but try to complete it without them if you can.\n",
        "\n",
        "Don't be discouraged if this challenge takes a few attempts to get correct. Working iteratively is a great way to work, and this challenge is more difficult than exercises you have previously completed.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "- Create a new column **roa** in the **f500** dataframe, containing the return on assets metric for each company.\n",
        "- Aggregate the data by the **sector** column, and create a dictionary **top_roa_by_sector**, with:\n",
        "  - Dictionary keys with the sector name.\n",
        "  - Dictionary values with the company name with the highest ROA value from that sector.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ih-EUDaMOLtz",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jmm3MDc8OYFy"
      },
      "source": [
        "In this lesson, we learned how to:\n",
        "\n",
        "- Select columns, rows and individual items using their integer location.\n",
        "- Use **pd.read_csv()** to read CSV files in pandas.\n",
        "- Work with integer axis labels.\n",
        "- How to use pandas methods to produce boolean arrays.\n",
        "- Use boolean operators to combine boolean comparisons to perform more complex analysis.\n",
        "- Use index labels to align data.\n",
        "- Use aggregation to perform advanced analysis using loops.\n",
        "\n",
        "In the next lecture, we'll learn techniques to use when performing data cleaning to prepare a messy data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMp5FFy_3UBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}